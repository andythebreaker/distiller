{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pymysql\n",
    "sys.path.append(\"../..\")\n",
    "page_G=\"Collect_activation_statistics\"\n",
    "def sqllog(strin):\n",
    "    global page_G\n",
    "    strin_=str(strin)\n",
    "    strin_=strin_.replace(\"'\", '\"')\n",
    "    #資料庫連線設定\n",
    "    db = pymysql.connect(host='localhost', port=3306, user='admin_user', passwd='admin', db='ai23', charset='utf8')\n",
    "    #建立操作游標\n",
    "    cursor = db.cursor()\n",
    "    #SQL語法\n",
    "    sql = \"INSERT INTO `ai23`.`\"+str(page_G)+\"` (`str`) VALUES ('\"+str(strin_)+\"');\"\n",
    "    #執行語法\n",
    "\n",
    "    try:\n",
    "      cursor.execute(sql)\n",
    "      #提交修改\n",
    "      db.commit()\n",
    "      #print('success')\n",
    "    except:\n",
    "      #發生錯誤時停止執行SQL\n",
    "      db.rollback()\n",
    "      print('SQLerror')\n",
    "\n",
    "    #關閉連線\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we show how to quantize recurrent models.  \n",
    "Using a pretrained model `model.RNNModel`, we convert the built-in pytorch implementation of LSTM to our own, modular implementation.  \n",
    "The pretrained model was generated with:  \n",
    "```time python3 main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --tied --wd=1e-6```  \n",
    "The reason we replace the LSTM that is because the inner operations in the pytorch implementation are not accessible to us, but we still want to quantize these operations. <br />\n",
    "Afterwards we can try different techniques to quantize the whole model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/macroai1/anaconda3/envs/ai23_37/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "from model import DistillerRNNModel, RNNModel\n",
    "from data import Corpus\n",
    "import torch\n",
    "from torch import nn\n",
    "import distiller\n",
    "from distiller.modules import DistillerLSTM as LSTM\n",
    "from tqdm import tqdm # for pretty progress bar\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='default', module='distiller.quantization')\n",
    "warnings.filterwarnings(action='default', module='distiller.quantization.range_linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('./data/wikitext-2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "device = 'cuda:0'\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(corpus.train, batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model and converting to our own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (encoder): Embedding(33278, 200)\n",
       "  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)\n",
       "  (decoder): Linear(in_features=200, out_features=33278, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model = torch.load('./checkpoint.pth.tar.best')\n",
    "rnn_model = rnn_model.to(device)\n",
    "rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the pytorch LSTM implementation to our own, by calling `LSTM.from_pytorch_impl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillerRNNModel(\n",
       "  (encoder): Embedding(33278, 200)\n",
       "  (rnn): DistillerLSTM(200, 200, num_layers=2, dropout=0.20, bidirectional=False)\n",
       "  (decoder): Linear(in_features=200, out_features=33278, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_model(pytorch_model_: RNNModel):\n",
    "    nlayers, ninp, nhid, ntoken, tie_weights = \\\n",
    "        pytorch_model_.nlayers, \\\n",
    "        pytorch_model_.ninp, \\\n",
    "        pytorch_model_.nhid, \\\n",
    "        pytorch_model_.ntoken, \\\n",
    "        pytorch_model_.tie_weights\n",
    "\n",
    "    model = DistillerRNNModel(nlayers=nlayers, ninp=ninp, nhid=nhid, ntoken=ntoken, tie_weights=tie_weights).to(device)\n",
    "    model.eval()\n",
    "    model.encoder.weight = nn.Parameter(pytorch_model_.encoder.weight.clone().detach())\n",
    "    model.decoder.weight = nn.Parameter(pytorch_model_.decoder.weight.clone().detach())\n",
    "    model.decoder.bias = nn.Parameter(pytorch_model_.decoder.bias.clone().detach())\n",
    "    model.rnn = LSTM.from_pytorch_impl(pytorch_model_.rnn)\n",
    "\n",
    "    return model\n",
    "\n",
    "man_model = manual_model(rnn_model)\n",
    "torch.save(man_model, 'manual.checkpoint.pth.tar')\n",
    "man_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching the data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 35\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(sequence_len, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target\n",
    "\n",
    "hidden = rnn_model.init_hidden(eval_batch_size)\n",
    "data, targets = get_batch(test_data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the convertion has succeeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error in y: 0.000005\n"
     ]
    }
   ],
   "source": [
    "rnn_model.eval()\n",
    "man_model.eval()\n",
    "y_t, h_t = rnn_model(data, hidden)\n",
    "y_p, h_p = man_model(data, hidden)\n",
    "\n",
    "print(\"Max error in y: %f\" % (y_t-y_p).abs().max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "\n",
    "def evaluate(model, data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(eval_batch_size)\n",
    "    with torch.no_grad():\n",
    "        with tqdm(range(0, data_source.size(0), sequence_len)) as t:\n",
    "            # The line below was fixed as per: https://github.com/pytorch/examples/issues/214\n",
    "            for i in t:\n",
    "                data, targets = get_batch(data_source, i)\n",
    "                output, hidden = model(data, hidden)\n",
    "                #sqllog(output)\n",
    "                output_flat = output.view(-1, ntokens)\n",
    "                total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "                hidden = repackage_hidden(hidden)\n",
    "                avg_loss = total_loss / (i + 1)\n",
    "                t.set_postfix((('val_loss', avg_loss), ('ppl', np.exp(avg_loss))))\n",
    "    return total_loss / len(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect activation statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model uses activation statistics to determine how big the quantization range is. The bigger the range - the larger the round off error after quantization which leads to accuracy drop.  \n",
    "Our goal is to minimize the range s.t. it contains the absolute most of our data.  \n",
    "After that, we divide the range into chunks of equal size, according to the number of bits, and transform the data according to this scale factor.  \n",
    "Read more on scale factor calculation [in our docs](https://intellabs.github.io/distiller/algo_quantization.html).\n",
    "\n",
    "The class `QuantCalibrationStatsCollector` collects the statistics for defining the range $r = max - min$.  \n",
    "\n",
    "Each forward pass, the collector records the values of inputs and outputs, for each layer:\n",
    "- absolute over all batches min, max (stored in `min`, `max`)\n",
    "- average over batches, per batch min, max (stored in `avg_min`, `avg_max`)\n",
    "- mean\n",
    "- std\n",
    "- shape of output tensor  \n",
    "\n",
    "All these values can be used to define the range of quantization, e.g. we can use the absolute `min`, `max` to define the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from distiller.data_loggers import collect_quant_stats, QuantCalibrationStatsCollector\n",
    "\n",
    "man_model = torch.load('./manual.checkpoint.pth.tar')\n",
    "distiller.utils.assign_layer_fq_names(man_model)\n",
    "collector = QuantCalibrationStatsCollector(man_model)\n",
    "\n",
    "stats_file = './acts_quantization_stats.yaml'\n",
    "\n",
    "if not os.path.isfile(stats_file):\n",
    "    def eval_for_stats(model):\n",
    "        evaluate(man_model, val_data)\n",
    "    collect_quant_stats(man_model, eval_for_stats, save_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Model For Quantization\n",
    "  \n",
    "We quantize the model after the training has completed.  \n",
    "Here we check the baseline model perplexity, to have an idea how good the quantization is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Prepare_the_Model_For_Quantization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 622/622 [1:18:16<00:00,  6.38s/it, val_loss=4.95, ppl=141]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss:    4.94\t|\t ppl:  139.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from distiller.quantization import PostTrainLinearQuantizer, LinearQuantMode\n",
    "from copy import deepcopy\n",
    "\n",
    "# Load and evaluate the baseline model.\n",
    "man_model = torch.load('./manual.checkpoint.pth.tar')\n",
    "val_loss = evaluate(man_model, val_data)\n",
    "print('val_loss:%8.2f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do our magic - __Preparing the model for quantization__.  \n",
    "The quantizer replaces the layers in out model with their quantized versions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the quantizer\n",
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(man_model),\n",
    "    model_activation_stats=stats_file)\n",
    "\n",
    "# Quantizer magic\n",
    "stats_before_prepare = deepcopy(quantizer.model_activation_stats)\n",
    "dummy_input = (torch.zeros(1,1).to(dtype=torch.long), man_model.init_hidden(1))\n",
    "quantizer.prepare_model(dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net-Aware Quantization\n",
    "\n",
    "Note that we passes a dummy input to `prepare_model`. This is required for the quantizer to be able to create a graph representation of the model, and to infer the connectivity between the modules.  \n",
    "Understanding the connectivity of the model is required to enable **\"Net-aware quantization\"**. This term (coined in [\\[1\\]](#references), section 3.2.2), means we can achieve better quantization by considering sequences of operations.  \n",
    "In the case of LSTM, we have an element-wise add operation whose output is split into 4 and fed into either Tanh or Sigmoid activations. Both of these ops saturate at relatively small input values - tanh at approximately $|4|$, and sigmoid saturates at approximately $|6|$. This means we can safely clip the output of the element-wise add operation between $[-6,6]$. `PostTrainLinearQuantizer` detects this patterm and modifies the statistics accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats BEFORE prepare_model:\n",
      "OrderedDict([('min', -15.612003326416016),\n",
      "             ('max', 15.450967788696289),\n",
      "             ('avg_min', -6.393781979404043),\n",
      "             ('avg_max', 5.522592915806375),\n",
      "             ('mean', -0.7798242293363614),\n",
      "             ('std', 1.3385719958875721),\n",
      "             ('shape', '(10, 6000)')])\n",
      "\n",
      "Stats AFTER to prepare_model:\n",
      "OrderedDict([('min', -6.0),\n",
      "             ('max', 6.0),\n",
      "             ('avg_min', -6.0),\n",
      "             ('avg_max', 5.522592915806375),\n",
      "             ('mean', -0.7798242293363614),\n",
      "             ('std', 1.3385719958875721),\n",
      "             ('shape', '(10, 6000)')])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "print('Stats BEFORE prepare_model:')\n",
    "pp.pprint(stats_before_prepare['rnn.cells.0.eltwiseadd_gate']['output'])\n",
    "\n",
    "print('\\nStats AFTER to prepare_model:')\n",
    "pp.pprint(quantizer.model_activation_stats['rnn.cells.0.eltwiseadd_gate']['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the value for `avg_max` did not change, since it was already below the clipping value of $6.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Quantized Model\n",
    "\n",
    "Let's see how the model has after being prepared for quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillerRNNModel(\n",
       "  (encoder): RangeLinearEmbeddingWrapper(\n",
       "    (wrapped_module): Embedding(33278, 200)\n",
       "  )\n",
       "  (rnn): DistillerLSTM(200, 200, num_layers=2, dropout=0.20, bidirectional=False)\n",
       "  (decoder): RangeLinearQuantParamLayerWrapper(\n",
       "    weights_quant_settings=(num_bits=8 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
       "    output_quant_settings=(num_bits=8 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
       "    accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
       "      inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n",
       "    scale_approx_mult_bits=None\n",
       "    preset_activation_stats=True\n",
       "      output_scale=3.670504, output_zero_point=0.000000\n",
       "    weights_scale=38.034809, weights_zero_point=0.000000\n",
       "    (wrapped_module): Linear(in_features=200, out_features=33278, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how `encoder` and `decoder` have been replaced with wrapper layers (for the relevant module type), which handle the quantization. The same holds for the internal layers of the `DistillerLSTM` module, which we don't print for brevity sake. To \"peek\" inside the `DistillerLSTM` module, we need to access it directly. As an example, let's take a look at a couple of the internal layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeLinearQuantParamLayerWrapper(\n",
      "  weights_quant_settings=(num_bits=8 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
      "  output_quant_settings=(num_bits=8 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
      "  accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
      "    inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n",
      "  scale_approx_mult_bits=None\n",
      "  preset_activation_stats=True\n",
      "    output_scale=17.780996, output_zero_point=0.000000\n",
      "  weights_scale=29.729475, weights_zero_point=0.000000\n",
      "  (wrapped_module): Linear(in_features=200, out_features=800, bias=True)\n",
      ")\n",
      "RangeLinearQuantEltwiseAddWrapper(\n",
      "  output_quant_settings=(num_bits=8 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
      "  accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
      "    inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n",
      "  scale_approx_mult_bits=None\n",
      "  preset_activation_stats=True\n",
      "    output_scale=21.250000, output_zero_point=0.000000\n",
      "  (wrapped_module): EltwiseAdd()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantizer.model.rnn.cells[0].fc_gate_x)\n",
    "print(quantizer.model.rnn.cells[0].eltwiseadd_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running the Quantized Model\n",
    "\n",
    "### Try 1: Initial settings - simple symmetric quantization\n",
    "\n",
    "Finally, let's go ahead and evaluate the quantized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Try_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 622/622 [1:10:30<00:00,  6.50s/it, val_loss=5.09, ppl=162]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss:    5.08\t|\t ppl:  161.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate(quantizer.model.to(device), val_data)\n",
    "print('val_loss:%8.2f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, the perplexity has increased much - meaning our quantization has damaged the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 2: Assymetric, per-channel\n",
    "\n",
    "Let's try quantizing each channel separately, and making the range of the quantization asymmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistillerRNNModel(\n",
       "  (encoder): RangeLinearEmbeddingWrapper(\n",
       "    (wrapped_module): Embedding(33278, 200)\n",
       "  )\n",
       "  (rnn): DistillerLSTM(200, 200, num_layers=2, dropout=0.20, bidirectional=False)\n",
       "  (decoder): RangeLinearQuantParamLayerWrapper(\n",
       "    weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_SIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n",
       "    output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_SIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
       "    accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n",
       "      inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n",
       "    scale_approx_mult_bits=None\n",
       "    preset_activation_stats=True\n",
       "      output_scale=5.024112, output_zero_point=48.000000\n",
       "    weights_scale=PerCh, weights_zero_point=PerCh\n",
       "    (wrapped_module): Linear(in_features=200, out_features=33278, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(man_model),\n",
    "    model_activation_stats=stats_file,\n",
    "    mode=LinearQuantMode.ASYMMETRIC_SIGNED,\n",
    "    per_channel_wts=True\n",
    ")\n",
    "quantizer.prepare_model(dummy_input)\n",
    "quantizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Try_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/622 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 1/622 [00:00<03:02,  3.41it/s, val_loss=167, ppl=4.45e+72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                      | 2/622 [00:00<02:56,  3.50it/s, val_loss=9.65, ppl=1.55e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                      | 3/622 [00:00<02:53,  3.57it/s, val_loss=7.41, ppl=1.66e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                          | 4/622 [00:01<02:52,  3.59it/s, val_loss=6.71, ppl=821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                          | 5/622 [00:01<02:49,  3.64it/s, val_loss=6.26, ppl=522]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 6/622 [00:01<02:43,  3.78it/s, val_loss=5.98, ppl=395]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 7/622 [00:01<02:38,  3.87it/s, val_loss=5.73, ppl=309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                          | 8/622 [00:02<02:39,  3.84it/s, val_loss=5.63, ppl=279]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                          | 9/622 [00:02<02:37,  3.88it/s, val_loss=5.55, ppl=258]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                         | 10/622 [00:02<02:36,  3.92it/s, val_loss=5.46, ppl=234]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                          | 11/622 [00:02<02:36,  3.90it/s, val_loss=5.4, ppl=222]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                         | 12/622 [00:03<02:36,  3.89it/s, val_loss=5.37, ppl=214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                         | 13/622 [00:03<02:35,  3.92it/s, val_loss=5.38, ppl=217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                         | 14/622 [00:03<02:31,  4.02it/s, val_loss=5.37, ppl=215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█                                         | 15/622 [00:04<04:54,  2.06it/s, val_loss=5.37, ppl=216]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                         | 16/622 [00:04<04:12,  2.40it/s, val_loss=5.33, ppl=207]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                        | 17/622 [00:05<03:40,  2.75it/s, val_loss=5.34, ppl=209]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                         | 18/622 [00:05<03:20,  3.01it/s, val_loss=5.3, ppl=200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                        | 19/622 [00:05<03:04,  3.28it/s, val_loss=5.26, ppl=192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                        | 20/622 [00:05<02:56,  3.40it/s, val_loss=5.25, ppl=191]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                        | 21/622 [00:06<02:45,  3.63it/s, val_loss=5.23, ppl=187]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                         | 22/622 [00:06<02:44,  3.66it/s, val_loss=5.2, ppl=181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                        | 23/622 [00:06<02:44,  3.65it/s, val_loss=5.19, ppl=179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                        | 24/622 [00:06<02:44,  3.64it/s, val_loss=5.18, ppl=178]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                        | 25/622 [00:07<02:40,  3.71it/s, val_loss=5.18, ppl=177]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▊                                        | 26/622 [00:07<02:41,  3.69it/s, val_loss=5.17, ppl=176]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▊                                        | 27/622 [00:07<02:42,  3.67it/s, val_loss=5.17, ppl=175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                        | 28/622 [00:08<02:36,  3.80it/s, val_loss=5.17, ppl=175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                        | 29/622 [00:08<02:36,  3.78it/s, val_loss=5.17, ppl=175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                        | 30/622 [00:08<02:38,  3.73it/s, val_loss=5.15, ppl=172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                        | 31/622 [00:08<02:35,  3.79it/s, val_loss=5.15, ppl=172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                       | 32/622 [00:09<02:39,  3.70it/s, val_loss=5.14, ppl=170]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                       | 33/622 [00:09<02:35,  3.79it/s, val_loss=5.13, ppl=169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▎                                       | 34/622 [00:09<02:34,  3.81it/s, val_loss=5.12, ppl=168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                       | 35/622 [00:10<04:35,  2.13it/s, val_loss=5.12, ppl=167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                        | 36/622 [00:10<03:57,  2.47it/s, val_loss=5.1, ppl=165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                        | 37/622 [00:11<03:29,  2.79it/s, val_loss=5.1, ppl=165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                       | 38/622 [00:11<03:10,  3.07it/s, val_loss=5.11, ppl=166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▋                                       | 39/622 [00:11<02:56,  3.30it/s, val_loss=5.11, ppl=166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▋                                       | 40/622 [00:11<02:45,  3.51it/s, val_loss=5.11, ppl=166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                       | 41/622 [00:12<02:39,  3.64it/s, val_loss=5.11, ppl=165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                       | 42/622 [00:12<02:35,  3.74it/s, val_loss=5.09, ppl=162]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                       | 43/622 [00:12<02:33,  3.78it/s, val_loss=5.09, ppl=163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                       | 44/622 [00:12<02:36,  3.70it/s, val_loss=5.09, ppl=163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███                                       | 45/622 [00:13<02:35,  3.71it/s, val_loss=5.09, ppl=162]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███▏                                       | 46/622 [00:13<02:33,  3.76it/s, val_loss=5.1, ppl=164]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                      | 47/622 [00:13<02:30,  3.83it/s, val_loss=5.11, ppl=166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n",
      "!debug!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_237973/1136580358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss:%8.2f\\t|\\t ppl:%8.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_237973/667129560.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_source)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0msqllog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0moutput_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai23_37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai2023final/distiller/examples/word_language_model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai23_37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai2023final/distiller/distiller/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai2023final/distiller/distiller/modules/rnn.py\u001b[0m in \u001b[0;36mprocess_layer_wise\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_chain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai2023final/distiller/distiller/modules/rnn.py\u001b[0m in \u001b[0;36m_layer_chain_unidirectional\u001b[0;34m(self, step, h)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai23_37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai2023final/distiller/distiller/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mfc_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meltwiseadd_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_gate_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_gate_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meltwisemult_cell_forget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meltwisemult_cell_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meltwiseadd_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai23_37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai2023final/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbuffer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0minputs_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai23_37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_buffers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                         raise TypeError(\"cannot assign '{}' as buffer '{}' \"\n\u001b[1;32m    625\u001b[0m                                         \u001b[0;34m\"(torch.Tensor or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_loss = evaluate(quantizer.model.to(device), val_data)\n",
    "print('val_loss:%8.2f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tiny bit better, but still no good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 3: Mixed FP16 and INT8\n",
    "\n",
    "Let us try the half precision (aka FP16) version of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Try_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp16 = deepcopy(man_model).half()\n",
    "val_loss = evaluate(model_fp16, val_data)\n",
    "print('val_loss: %8.6f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is very close to our original model! That means that the roundoff when quantizing linearly to 8-bit integers is what hurts our accuracy.\n",
    "\n",
    "Luckily, `PostTrainLinearQuantizer` supports quantizing some/all layers to FP16 using the `fp16` parameter. In light of what we just saw, and as stated in [\\[2\\]](#References), let's try keeping element-wise operations at FP16, and quantize everything else to 8-bit using the same settings as in try 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides_yaml = \"\"\"\n",
    ".*eltwise.*:\n",
    "    fp16: true\n",
    "encoder:\n",
    "    fp16: true\n",
    "decoder:\n",
    "    fp16: true\n",
    "\"\"\"\n",
    "overrides = distiller.utils.yaml_ordered_load(overrides_yaml)\n",
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(man_model),\n",
    "    model_activation_stats=stats_file,\n",
    "    mode=LinearQuantMode.ASYMMETRIC_SIGNED,\n",
    "    overrides=overrides,\n",
    "    per_channel_wts=True\n",
    ")\n",
    "quantizer.prepare_model(dummy_input)\n",
    "quantizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Try_32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = evaluate(quantizer.model.to(device), val_data)\n",
    "print('val_loss:%8.6f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is still holding up very well, even though we quantized the inner linear layers!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 4: Clipping Activations\n",
    "\n",
    "Now, lets try to choose different boundaries for `min`, `max`.  \n",
    "Instead of using absolute ones, we take the average of all batches (`avg_min`, `avg_max`), which is an indication of where usually most of the boundaries lie. This is done by specifying the `clip_acts` parameter to `ClipMode.AVG` or `\"AVG\"` in the quantizer ctor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Try_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides_yaml = \"\"\"\n",
    "encoder:\n",
    "    fp16: true\n",
    "decoder:\n",
    "    fp16: true\n",
    "\"\"\"\n",
    "overrides = distiller.utils.yaml_ordered_load(overrides_yaml)\n",
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(man_model),\n",
    "    model_activation_stats=stats_file,\n",
    "    mode=LinearQuantMode.ASYMMETRIC_SIGNED,\n",
    "    overrides=overrides,\n",
    "    per_channel_wts=True,\n",
    "    clip_acts=\"AVG\"\n",
    ")\n",
    "quantizer.prepare_model(dummy_input)\n",
    "val_loss = evaluate(quantizer.model.to(device), val_data)\n",
    "print('val_loss:%8.6f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Even though we quantized all of the layers except the embedding and the decoder - we got almost no accuracy penalty. Lets try quantizing them as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_G=\"Try_f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(man_model),\n",
    "    model_activation_stats=stats_file,\n",
    "    mode=LinearQuantMode.ASYMMETRIC_SIGNED,\n",
    "    per_channel_wts=True,\n",
    "    clip_acts=\"AVG\"\n",
    ")\n",
    "quantizer.prepare_model(dummy_input)\n",
    "val_loss = evaluate(quantizer.model.to(device), val_data)\n",
    "print('val_loss:%8.6f\\t|\\t ppl:%8.2f' % (val_loss, np.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that sometimes quantizing with the right boundaries gives better results than actually using floating point operations (even though they are half precision). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Choosing the right boundaries for quantization  was crucial for achieving almost no degradation in accrucay of LSTM.  \n",
    "  \n",
    "Here we showed how to use the Distiller quantization API to quantize an RNN model, by converting the PyTorch implementation into a modular one and then quantizing each layer separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. **Jongsoo Park, Maxim Naumov, Protonu Basu, Summer Deng, Aravind Kalaiah, Daya Khudia, James Law, Parth Malani, Andrey Malevich, Satish Nadathur, Juan Miguel Pino, Martin Schatz, Alexander Sidorov, Viswanath Sivakumar, Andrew Tulloch, Xiaodong Wang, Yiming Wu, Hector Yuen, Utku Diril, Dmytro Dzhulgakov, Kim Hazelwood, Bill Jia, Yangqing Jia, Lin Qiao, Vijay Rao, Nadav Rotem, Sungjoo Yoo, Mikhail Smelyanskiy**. Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications. [arxiv:1811.09886](https://arxiv.org/abs/1811.09886)\n",
    "\n",
    "2. **Qinyao He, He Wen, Shuchang Zhou, Yuxin Wu, Cong Yao, Xinyu Zhou, Yuheng Zou**. Effective Quantization Methods for Recurrent Neural Networks. [arxiv:1611.10176](https://arxiv.org/abs/1611.10176)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai23_37",
   "language": "python",
   "name": "ai23_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
